{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce6294-6f65-44dd-b372-c764107bae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"所有跨文件的全局变量由本模块计算并赋值\n",
    "\n",
    "其他模块需要使用本模块全局变量时，在模块开头导入本模块即可\n",
    "例子：\n",
    "    from setting import *...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# 在pycharm的用户环境变量配置好科大讯飞的APP_ID和secretkey\n",
    "LFASR_APP_ID = os.getenv(\"LFASR_APP_ID\")\n",
    "LFASR_SECRETKEY = os.getenv(\"LFASR_SECRETKEY\")\n",
    "\n",
    "# 获取当前工作目录的绝对路径\n",
    "current_directory = Path.cwd()\n",
    "# 获取根目录（上两级）\n",
    "root_directory = current_directory.parents[0]\n",
    "# 将根目录添加到系统路径中\n",
    "sys.path.append(str(root_directory))\n",
    "ROOT = Path(os.path.relpath(root_directory, Path.cwd()))  # relative\n",
    "\n",
    "# data\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw_data\"\n",
    "RESULT_DATA_DIR = DATA_DIR / \"result_data\"\n",
    "FREQ_CSV = \"调号音符频率表.csv\"\n",
    "SONGNAME_CSV = \"文件歌曲表.csv\"\n",
    "SCORE_CSV = \"文件评分表.csv\"\n",
    "RESULT_CSV = \"模型结果表.csv\"\n",
    "EVALUATE_CSV = \"评估结果表.csv\"\n",
    "INDEX_CSV = \"指标结果表.csv\"\n",
    "\n",
    "# eigen_json\n",
    "EIGEN_DIR = ROOT / \"eigen_json\"\n",
    "\n",
    "# audio\n",
    "UPLOAD_FILE_DIR = ROOT / \"audio\"\n",
    "\n",
    "# resultJson\n",
    "DOWNLOAD_DIR = ROOT / \"resultJson\"\n",
    "\n",
    "# lyrics\n",
    "LYRICS_DIR = ROOT / \"lyrics\"\n",
    "\n",
    "# resultAudio\n",
    "AUDIO_DIR = ROOT / \"resultAudio\"\n",
    "\n",
    "# json结果的名字后缀\n",
    "OUTPUT_JSON_NAME = \"orderResult.json\"\n",
    "\n",
    "# 预处理后的audio的后缀\n",
    "OUTPUT_AUDIO_NAME = \"seg.wav\"\n",
    "\n",
    "# 测试脚手架\n",
    "TEST_DIR = ROOT / \"test_space\"\n",
    "TEST_AUDIO_DIR = TEST_DIR / \"audio\"\n",
    "TEST_EIGEN_DIR = TEST_DIR / \"eigen_json\"\n",
    "TEST_RESULT_DIR = TEST_DIR / \"orderResult_example\"\n",
    "TEST_AUDIO_EIGEN_DIR = TEST_DIR / \"audio_eigen_test\"\n",
    "TEST_DATA_DIR = TEST_DIR / \"data\"\n",
    "TEST_RAWDATA_DIR = TEST_DATA_DIR / \"raw_data\"\n",
    "TEST_RESULTDATA_DIR = TEST_DATA_DIR / \"result_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8be96-4b75-4d82-a594-935a0e25321b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from funasr import AutoModel\n",
    "import librosa\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dtw import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17070d3f-a360-452e-aa96-a20af365f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(data: list):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee6879-2453-4524-9847-f8122154c73c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def funasr_run(\n",
    "    model: str = \"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\",\n",
    "    vad_model: str = \"fsmn-vad\",\n",
    "    punc_model: str = \"ct-punc-c\",\n",
    "    input_audio_dir: Path = UPLOAD_FILE_DIR,\n",
    "    input_audio_dataset: str = None,\n",
    "    input_audio_name: str = None,\n",
    "    input_parsed_audio: np.ndarray = None,\n",
    "    input_mode: str = \"file\",\n",
    "    download_json_dir: Path = DOWNLOAD_DIR,\n",
    ") -> dict:\n",
    "    \"\"\"使用funasr进行ASR（语音识别）,输出识别文字以及每个字的时间戳\n",
    "\n",
    "    参数：\n",
    "        model(str):\n",
    "            选用的模型，默认为\"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\"，如何选择模型详见达摩院Paraformer large\n",
    "        vad_model(str):\n",
    "            语音活动检测选用的模型，默认为fsmn-vad\n",
    "        punc_model(str):\n",
    "            标点检测选用的模型，默认为ct-punc-c\n",
    "        input_audio_dir(Path):\n",
    "            待识别音频所处的爷目录，默认为UPLOAD_FILE_DIR\n",
    "        input_audio_dataset(str):\n",
    "            待识别音频所处的数据集名称\n",
    "        input_audio_name(str):\n",
    "            音频文件名（带后缀）\n",
    "        input_parsed_audio(np.ndarray):\n",
    "            已解析的audio信号序列\n",
    "        input_mode(str):\n",
    "            输入的形式，包括：\n",
    "                file：输入音频文件\n",
    "                parsed：输入已解析的audio信号序列\n",
    "        download_json_dir(Path):\n",
    "            输出结果保存为json的爷目录，默认为DOWNLOAD_DIR\n",
    "\n",
    "    返回：\n",
    "        rs_dict(dict):\n",
    "            只有一个元素的列表，元素为字典，结构如下：\n",
    "                key（str）:\n",
    "                    随机种子\n",
    "                text（str）:\n",
    "                    识别文本\n",
    "                timestamp(list):\n",
    "                    识别文本每个字的时间戳\n",
    "    \"\"\"\n",
    "    if input_audio_name is not None:\n",
    "        path_str = str(input_audio_dir / input_audio_dataset / input_audio_name)\n",
    "    download_dir = download_json_dir / input_audio_dataset\n",
    "    if not download_dir.exists():\n",
    "        download_dir.mkdir(parents=True)\n",
    "\n",
    "    real_audio_name = re.sub(r'\\..*', '', input_audio_name)\n",
    "    json_name = real_audio_name + '.json'\n",
    "    download_path = download_dir / json_name\n",
    "\n",
    "    if not download_path.exists():\n",
    "        model = AutoModel(\n",
    "            model=model,\n",
    "            model_revision=\"v2.0.4\",\n",
    "            vad_model=vad_model,\n",
    "            vad_model_revision=\"v2.0.4\",\n",
    "            punc_model=punc_model,\n",
    "            punc_model_revision=\"v2.0.4\",\n",
    "        )\n",
    "        if input_mode == \"file\":\n",
    "            rs_list = model.generate(input=path_str, batch_size_s=300)\n",
    "        elif input_mode == \"parsed\":\n",
    "            rs_list = model.generate(input=input_parsed_audio, batch_size_s=300)\n",
    "\n",
    "        rs_dict = rs_list[0]\n",
    "\n",
    "        with open(download_path, \"w\", encoding=\"gbk\") as json_file:\n",
    "            json.dump(rs_dict, json_file, indent=2, ensure_ascii=False)\n",
    "    else:\n",
    "        with open(download_path, \"r\", encoding=\"gbk\") as file:\n",
    "            rs_dict = json.load(file)\n",
    "\n",
    "    return rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ad9bf-a76d-44d3-910c-1898fcfdbe97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getWordInfoList(funasr_dict: dict) -> dict:\n",
    "    \"\"\"提供类似funasr_run输出结果的列表，生成一个eigen_list字典\n",
    "\n",
    "    详细生成结果例子见ROOT / \"orderResult_example\"   / \"getWordInfoList_result.json\"\n",
    "\n",
    "    参数：\n",
    "        funasr_dict(dict)：\n",
    "            funasr_run输出结果形式的列表\n",
    "\n",
    "    返回：\n",
    "        eigen_dict(dict)：\n",
    "            结构如下：\n",
    "            eigen_list(list[dict])\n",
    "                    word(str):字\n",
    "                    eigen(dict)\n",
    "                        start_time(float)\n",
    "                        end_time(float)\n",
    "    \"\"\"\n",
    "    text = funasr_dict[\"text\"]\n",
    "    time = funasr_dict[\"timestamp\"]\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]+\", \"\", text)\n",
    "\n",
    "    eigen_dict = {\"eigen_list\": []}\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        eigen_dict_item = {\"word\": \"\", \"eigen\": {}}\n",
    "        eigen = eigen_dict_item[\"eigen\"]\n",
    "\n",
    "        eigen_dict_item[\"word\"] = text[i]\n",
    "\n",
    "        eigen[\"start_time\"] = round(time[i][0] / 1000, 3)\n",
    "        # 检验与下一个字之间的时间差，<2秒则意味着中间无明显间隔\n",
    "        if (i < len(text) - 1) and (time[i + 1][0] - time[i][1] <= 2000):\n",
    "            eigen[\"end_time\"] = round(time[i + 1][0] / 1000, 3)\n",
    "        else:\n",
    "            eigen[\"end_time\"] = round(time[i][1] / 1000, 4)\n",
    "\n",
    "        eigen_dict[\"eigen_list\"].append(eigen_dict_item)\n",
    "\n",
    "    return eigen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2fc41-d11f-4637-bf9b-0dee4aac8c68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calAudioFreq(\n",
    "    reduced_noise: np.ndarray, sr: int, fmax: float = 2093.0, fmin: float = 65.0\n",
    ") -> tuple:\n",
    "    \"\"\"使用Pyin算法来估计各时刻的基音频率，生成一个元组，包括基频列表和基频对应的times列表.\n",
    "\n",
    "    reduced_noise:\n",
    "        noiseReduce的返回结果。\n",
    "    sr：\n",
    "        noiseReduce的返回的采样率。\n",
    "    fmax：\n",
    "        估计的最大频率，默认为2093.0。\n",
    "    fmin:\n",
    "        估计的最小频率，默认为65.0。\n",
    "\n",
    "    返回：\n",
    "        Freq_list：\n",
    "            基频列表。\n",
    "        times_list：\n",
    "            各基频对应的times的列表。\n",
    "    \"\"\"\n",
    "    # Freq_list 以赫兹为单位的基频时间序列。voiced_flag 包含指示帧是否有声的布尔标志的时间序列；voiced_probs 包含帧有声概率的时间序列。\n",
    "    Freq_list, voiced_flag, voiced_probs = librosa.pyin(\n",
    "        y=reduced_noise, sr=sr, fmin=fmin, fmax=fmax\n",
    "    )\n",
    "\n",
    "    times_list = librosa.times_like(Freq_list)\n",
    "    Freq_list = Freq_list.tolist()\n",
    "    times_list = times_list.tolist()\n",
    "    return Freq_list, times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cea32c-d34e-4927-8f6a-37f5f3480b8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"模块功能描述\n",
    "\n",
    "简谱特征提取模块，通过定义extractJson、calNoteTime、calNoteFreq方法，分别将JSON简谱文件识别并提取为字典格式后，通过曲子的BPM和拍号\n",
    "计算出每个歌词的音长，最后算出每个切割后的词所对应的频率。\n",
    "\n",
    "经典的使用示例：\n",
    "\n",
    "data = extractJson()\n",
    "eigen_dict_t = calNoteTime(eigen_dict = data)\n",
    "eigen_dict_rs = calNoteFreq()\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extractJson(json_dir: Path = EIGEN_DIR, json_name: str = None):\n",
    "    \"\"\"提取json文件，将其输出为字典格式。\n",
    "\n",
    "    通过指定的路径，将JSON文件的内容识别出来，并转为dict格式输出。\n",
    "\n",
    "    参数：\n",
    "        json_dir：\n",
    "            根目录，eg：EIGEN_DIR = ROOT / \"eigen_json\"。\n",
    "        json_name：\n",
    "            去掉尾缀后的文件名，eg：self.json_name = \"中华人民共和国国歌测试\"。\n",
    "\n",
    "    返回：\n",
    "        eigen_dict为从JSON文件中提出的结果。\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    json_name = json_name + \".json\"\n",
    "    json_filename = os.path.join(json_dir, json_name)\n",
    "    '''使用with方法，文件加载后赋值给data后会自动关闭，无需写代码手动关闭'''\n",
    "    with open(json_filename, \"r\", encoding=\"gbk\") as f:\n",
    "        data = json.load(f)\n",
    "    eigen_dict = data\n",
    "    return eigen_dict\n",
    "\n",
    "\n",
    "def calNoteTime(eigen_dict: dict) -> dict:\n",
    "    \"\"\"传入extractJson的输出结果，根据bpm和time_signature来计算所有note对应的音长，单位为秒\n",
    "\n",
    "    音长的计算公式为：（60÷BPM）×（拍号的分母/4）× 每个词的拍数\n",
    "\n",
    "    参数：eigen_dict：\n",
    "        将extractJson读取的JSON文件结果传进来。\n",
    "\n",
    "    返回：\n",
    "        eigen_dict_t:\n",
    "            原始JSON中time键所对应的value值替换为音长\n",
    "    \"\"\"\n",
    "    bpm = eigen_dict[\"bpm\"]  # 存储简谱中的BPM值\n",
    "    note = eigen_dict[\"time_signature\"][1]\n",
    "\n",
    "    \"\"\"遍历文件eigen_dict下的eigen_list键中所嵌套的dict值，将子键值对eigen中将time提取出来，通过公式计算后的音长替换掉原来的时间\"\"\"\n",
    "    eigen_list = eigen_dict[\"eigen_list\"]\n",
    "    for eigen in eigen_list:\n",
    "        time = eigen[\"eigen\"][\"time\"]\n",
    "        word_duration = [60 / bpm * note / 4 * t for t in time]\n",
    "        eigen[\"eigen\"][\"time\"] = word_duration\n",
    "    eigen_dict_t = eigen_dict\n",
    "\n",
    "    return eigen_dict_t\n",
    "\n",
    "\n",
    "def calNoteFreq(\n",
    "    eigen_dict_t: dict, data_dir: Path = RAW_DATA_DIR, data_name: str = FREQ_CSV, note_sig: str = None\n",
    ") -> dict:\n",
    "    \"\"\"传入calNoteTime的输出结果,计算每个词的频率。\n",
    "\n",
    "    根据raw_data中的调号音符频率表以及给定的调号，计算调号对应的简谱里所有音符的频率，单位为HZ，计算出简谱中eigen_list所有word对应的频率值，\n",
    "    并将计算出来的频率值替换掉以前的JSON文件中的note值。\n",
    "\n",
    "    参数：\n",
    "        eigen_dict_t：\n",
    "            calNoteTime处理后的JSON文件。\n",
    "        data_dir：\n",
    "            调号音符频率表所在目录的绝对路径,默认为RAW_DATA_DIR。\n",
    "        data_name：\n",
    "            调号音符频率表的名称，默认为FREQ_CSV。\n",
    "        note_sig：\n",
    "            调号，乐理中的概念。取值范围为调号频率表的音名1 列和音名2列取值范围。\n",
    "\n",
    "    返回：\n",
    "        eigen_dict_rs:\n",
    "            将calNoteTime处理后JSON中note键所对应的value值替换为频率\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    csv_filename = os.path.join(data_dir, data_name)  # 拼接csv文件所在的路径\n",
    "    df = pd.read_csv(csv_filename, encoding=\"gbk\")  # 读取音符频率表\n",
    "    # matched_rows为子表，根据传入的调号note_sig找出相应音名的子表\n",
    "    matched_rows = df[(df[\"音名1\"] == note_sig) | (df[\"音名2\"] == note_sig)]\n",
    "\n",
    "    # 在传进的JSON文件中，定位到多层键值对下的eigen_list，并将对应的键值对赋值给eigen_list\n",
    "    eigen_list = eigen_dict_t[\"eigen_list\"]\n",
    "\n",
    "    notes = []  # 用来存放JSON文件中的note键对应的value值\n",
    "    \"\"\"遍历eigen_list中所有的eigen下的子键值对，将note所对应的值存储到notes中，eg：notes=[['-5'], ['1'], ['1'], ['1'], ['+1'], ['-1', '--6']]\"\"\"\n",
    "    for eigen in eigen_list:\n",
    "        note = eigen[\"eigen\"][\"note\"]\n",
    "        notes.append(note)\n",
    "\n",
    "    \"\"\"第一层for循环进入到所有的子列表中，eg：['-5']，第二层for循环进入到该子列表中的数字，eg：-5，第三层for循环识别统计有多少个'+'，'-'符号\"\"\"\n",
    "    for sublist in notes:\n",
    "        for i in range(len(sublist)):\n",
    "            item = sublist[i]\n",
    "            negative_count = 0  # 用于统计'-'的个数\n",
    "            positive_count = 0  # 用于统计'+'的个数\n",
    "            numbers = []  # 用于存储第三层循环中除去符号后的数字，eg：'-5'——>5\n",
    "\n",
    "            for char in item:\n",
    "                if char == \"-\":\n",
    "                    negative_count += char.count(\"-\")\n",
    "                elif char == \"+\":\n",
    "                    positive_count += char.count(\"+\")\n",
    "\n",
    "            number = char.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "            numbers.append(number)\n",
    "            # 找出音名所对应的频率值\n",
    "            matched_freq = matched_rows[matched_rows[\"唱名\"] == number][\"频率\"].values\n",
    "            \"\"\"如果找到的频率值长度大于0，则取出，否则赋值为None\"\"\"\n",
    "            if len(matched_freq) > 0:\n",
    "                matched_freq = matched_freq[0]\n",
    "            else:\n",
    "                matched_freq = None\n",
    "            \"\"\"如果第二层循环取出的数字有'+'符号是，表示频率值需变为2的指数倍，eg：'++3'表示为，频率值为4倍（2的平方=4）音名3的频率；\n",
    "            取出的数字有'-'号表示频率值变为1/2的指数倍；如果没有'+'，'-'符号，则直接取出频率值\"\"\"\n",
    "            if negative_count > 0 and positive_count == 0:\n",
    "                matched_freq = matched_freq * 0.5**negative_count\n",
    "            elif positive_count > 0 and negative_count == 0:\n",
    "                matched_freq = matched_freq * 2**positive_count\n",
    "            else:\n",
    "                matched_freq = matched_freq\n",
    "            \"\"\"将计算出来的音符的频率值替换掉原JSON文件中的note的值，将替换放在第二层是因为遇到特殊子表['+1', '--6']时，可以不破坏子列表的结构也可以将计算后频率值放回\"\"\"\n",
    "            sublist[i] = matched_freq\n",
    "\n",
    "    eigen_dict_rs = eigen_dict_t\n",
    "\n",
    "    return eigen_dict_rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9e724-b9d5-440c-adff-9df15705b3ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getSheetMusicFeatDict(json_name: str = \"国歌\"):\n",
    "    key_sig_list = [\"A\", \"A#\", \"B\", \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\"]\n",
    "\n",
    "    notation_feat_dict = {}\n",
    "    for i in range(len(key_sig_list)):\n",
    "        eigen_dict = extractJson(json_name=json_name)\n",
    "        eigen_dict_t = calNoteTime(eigen_dict)\n",
    "        eigen_dict_rs = calNoteFreq(eigen_dict_t, note_sig=key_sig_list[i])\n",
    "        \n",
    "        # 进行深拷贝\n",
    "        eigen_dict_rs_copy = copy.deepcopy(eigen_dict_rs)\n",
    "\n",
    "        notation_feat_dict[key_sig_list[i]] = eigen_dict_rs\n",
    "\n",
    "        new_key_name = key_sig_list[i] + \"/2\"\n",
    "        # 遍历每个 eigen 字典，将 note 键对应的值除以 2\n",
    "        for item in eigen_dict_rs_copy['eigen_list']:\n",
    "            item['eigen']['note'] = [x / 2 for x in item['eigen']['note']]\n",
    "        notation_feat_dict[new_key_name] = eigen_dict_rs_copy\n",
    "            \n",
    "    return notation_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7b9f6-2bd5-42e2-8d8e-bbd2c1daa251",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getPerWordFeat(eigen_dict: dict, freq_list: list, times_list: list, crop_percent: float=0.2) -> dict:\n",
    "    \"\"\"根据adjustWordTime和calAudioFreq的结果来计算每个字的基频f0。\n",
    "\n",
    "    参数：\n",
    "        eigen_dict(dict)：\n",
    "            adjustWordTime的结果\n",
    "        freq_list(list)：\n",
    "            calAudioFreq的结果\n",
    "        times_list(list)：\n",
    "            calAudioFreq的结果\n",
    "        crop_percent(float)：\n",
    "            每个字的基频序列的裁剪比例，默认为0.2\n",
    "\n",
    "    返回：\n",
    "        rs_dict(dict)，结构如下：\n",
    "            eigen_list(list[dict])\n",
    "                word(str)\n",
    "                eigen(dict)\n",
    "                    start_time(float)\n",
    "                    end_time(float)\n",
    "                    times(float)\n",
    "                    freq(float)\n",
    "    \"\"\"\n",
    "    eigen_list = eigen_dict[\"eigen_list\"]\n",
    "    for i in range(len(eigen_list)):\n",
    "        item = eigen_list[i][\"eigen\"]\n",
    "        times = item[\"end_time\"]-item[\"start_time\"]\n",
    "        if times > 0.1:\n",
    "            seg_start_time = item[\"start_time\"]+times*crop_percent\n",
    "            seg_end_time = item[\"end_time\"]-times*crop_percent\n",
    "\n",
    "        indices = [\n",
    "            index for index, time in enumerate(times_list) if seg_start_time <= time <= seg_end_time\n",
    "        ]\n",
    "        freq_seq = [freq_list[index] for index in indices if not np.isnan(freq_list[index])]\n",
    "        item[\"freq\"] = round(np.median(freq_seq), 3)\n",
    "        item[\"times\"] = round(times, 3)\n",
    "\n",
    "    return eigen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a106967-8085-4ced-8c35-012930145c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dtw_freq_and_tempo(notation_feat_dict: dict, pwf_dict: dict):\n",
    "    # 提取pwf_dict 字典里的所有times和freq，分别按顺序得到times_list和freq_list\n",
    "    freq_list = [item[\"eigen\"][\"freq\"] for item in pwf_dict[\"eigen_list\"]]\n",
    "    times_list = [item[\"eigen\"][\"times\"] for item in pwf_dict[\"eigen_list\"]]\n",
    "    z_freq_list = z_score_normalization(freq_list)\n",
    "    z_times_list = z_score_normalization(times_list)\n",
    "\n",
    "    dtw_rs_dict = {}\n",
    "\n",
    "    # 提取notation_feat_dict 字典里的所有times和note，分别按顺序得到orignal_freq_list和orignal_times_list\n",
    "    for key in notation_feat_dict.keys():\n",
    "        orignal_freq_list = [\n",
    "            np.average(item[\"eigen\"][\"note\"], weights=item[\"eigen\"][\"time\"])\n",
    "            for item in notation_feat_dict[key][\"eigen_list\"]\n",
    "        ]\n",
    "        z_orignal_freq_list = z_score_normalization(orignal_freq_list)\n",
    "        freq_dtw_rs = dtw(z_freq_list, z_orignal_freq_list, dist_method='euclidean')\n",
    "\n",
    "        orignal_times_list = [\n",
    "            np.sum(item[\"eigen\"][\"time\"])\n",
    "            for item in notation_feat_dict[key][\"eigen_list\"]\n",
    "        ]\n",
    "        z_orignal_times_list = z_score_normalization(orignal_times_list)\n",
    "        tempo_dtw_rs = dtw(z_times_list, z_orignal_times_list, dist_method='euclidean')\n",
    "\n",
    "        dtw_rs_dict[key] = {}\n",
    "        # dtw_rs_dict[key][\"freq_dist_normalized\"] = freq_dtw_rs.normalizedDistance\n",
    "        # dtw_rs_dict[key][\"tempo_dist_normalized\"] = tempo_dtw_rs.normalizedDistance\n",
    "        dtw_rs_dict[key][\"freq_dist_normalized\"] = freq_dtw_rs.distance\n",
    "        dtw_rs_dict[key][\"tempo_dist_normalized\"] = tempo_dtw_rs.distance\n",
    "\n",
    "    return dtw_rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f716fc-e48c-44e3-9ec9-550df21964b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试funasr_run\n",
    "rs_dict = funasr_run(input_audio_dataset = \"qilai\", input_audio_name=\"cst.mp3\")\n",
    "# rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9b79c-be63-4e76-997f-7a9a3d46caee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试getWordInfoList\n",
    "eigen_dict = getWordInfoList(funasr_dict=rs_dict)\n",
    "# eigen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78bd76f-ff58-4e11-8f42-c58fd58ff47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 根据start_time 和end_time切割音频输出并画CQT色度图，检查音长边缘误差问题\n",
    "\n",
    "# audio = AudioSegment.from_file(r\"D:\\my_knowledge\\research_assistant\\python_project\\speech_recognition\\audio\\qilai\\cst.mp3\")\n",
    "# eigen_list = eigen_dict[\"eigen_list\"]\n",
    "# for i in range(len(eigen_list)):\n",
    "#     output_wav = f'{i}{eigen_list[i][\"word\"]}.wav'\n",
    "#     output_png = f'{i}{eigen_list[i][\"word\"]}.png'\n",
    "#     segment = audio[eigen_list[i][\"eigen\"][\"start_time\"] : eigen_list[i][\"eigen\"][\"end_time\"]]\n",
    "#     segment.export(ROOT / \"jupyter\" / \"cst_new\" / output_wav, format=\"wav\")\n",
    "#     seg_y, sr = librosa.load(ROOT / \"jupyter\" / \"cst_new\" / output_wav)\n",
    "\n",
    "#     chroma = librosa.feature.chroma_cqt(y=seg_y, sr=sr)\n",
    "#     bounds = librosa.segment.agglomerative(chroma, 2)\n",
    "#     bound_times = librosa.frames_to_time(bounds, sr=sr)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     trans = mpt.blended_transform_factory(\n",
    "#                 ax.transData, ax.transAxes)\n",
    "#     librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax)\n",
    "#     ax.vlines(bound_times, 0, 1, color='linen', linestyle='--',\n",
    "#               linewidth=2, alpha=0.9, label='Segment boundaries',\n",
    "#               transform=trans)\n",
    "#     ax.legend()\n",
    "#     ax.set(title='Power spectrogram')\n",
    "\n",
    "#     plt.savefig(ROOT / \"jupyter\" / \"cst_new\" / output_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c4dfa-af27-4cca-90b5-857982a6381c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试calAudioFreq\n",
    "y, sr = librosa.load(r\"D:\\my_knowledge\\research_assistant\\python_project\\speech_recognition\\audio\\cst.mp3\")\n",
    "freq_list, times_list = calAudioFreq(reduced_noise=y,sr=sr)\n",
    "# 画图\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "ax.set(title='pYIN fundamental frequency estimation')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "ax.plot(times_list, freq_list, label='f0', color='cyan', linewidth=3)\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd384d-3210-4508-929d-3ea1baf69286",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list, times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbefafc-3153-4dc4-879d-37002c078841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试getPerWordFeat\n",
    "pwf_dict = getPerWordFeat(eigen_dict=eigen_dict,freq_list=freq_list,times_list=times_list)\n",
    "# pwf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409214e-2580-4802-9f79-9e7d71c1089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试getSheetMusicFeatDict\n",
    "notation_feat_dict = getSheetMusicFeatDict()\n",
    "# notation_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9b210-8f32-4740-9745-a4d4c0856227",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_rs_dict = cal_dtw_freq_and_tempo(notation_feat_dict, pwf_dict)\n",
    "# dtw_rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fb6d1-f950-4b96-9f84-8120c796b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notation_feat_dict[\"E/2\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
